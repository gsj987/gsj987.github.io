<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.55.3" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归 | gsj987的博客</title>
    <meta property="og:title" content="Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归 - gsj987的博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content="2019-05-03T00:00:00&#43;08:00">
        
        
    <meta property="article:modified_time" content="2019-05-03T00:00:00&#43;08:00">
        
    <meta name="Keywords" content="架构,python,前端,xamarin,软件工程,机器学习,机器视觉,c#,angular">
    <meta name="description" content="Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归">
        
    <meta name="author" content="gsj987">
    <meta property="og:url" content="https://gsj987.github.io/posts/tensorflow-experience-2/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
        <link rel="stylesheet" href="/css/prism.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    


    
    
</head>

<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://gsj987.github.io/">
                        gsj987的博客
                    </a>
                
                <p class="description">技术学习和创业思考</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://gsj987.github.io/">首页</a>
                    
                    <a  href="https://gsj987.github.io/archives/" title="归档">归档</a>
                    
                    <a  href="https://gsj987.github.io/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <article class="post">
                        <header>
                            <h1 class="post-title">Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归</h1>
                        </header>
                        <date class="post-meta meta-date">
                            2019年5月3日
                        </date>
                        
                        <div class="post-meta">
                            <span>|</span>
                            
                                <span class="meta-category"><a href="https://gsj987.github.io/categories/machine-learning">machine-learning</a></span>
                            
                        </div>
                        
                        
                        
                        <div class="clear">
                            <div class="toc-article">
                                <div class="toc-title">文章目录</div>
                                <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#逻辑回归">逻辑回归</a>
<ul>
<li><a href="#损失函数">损失函数</a></li>
</ul></li>
<li><a href="#生成模拟数据">生成模拟数据</a></li>
<li><a href="#创建训练网络">创建训练网络</a></li>
<li><a href="#迭代训练">迭代训练</a></li>
<li><a href="#评估训练结果">评估训练结果</a></li>
<li><a href="#问题回顾">问题回顾</a></li>
<li><a href="#总结">总结</a></li>
</ul></li>
</ul>
</nav>
                            </div>
                        </div>
                        
                        <div class="post-content">
                            

<h2 id="逻辑回归">逻辑回归</h2>

<p>逻辑回归是机器学习中最重要的概念之一。所谓逻辑回归就是在几组数据集中，利用广义线性回归的方法，对数据进行分类的方法。虽然他叫回归，但本质上是利用回归方法做了分类。其使用前提是：</p>

<ol>
<li>数据符合伯努利二项分布<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>，也就是说各项分类之间相互独立，每次成功的概率为 p，即$x,y\sim B(\pm1,p)$</li>
<li>样本数据线性可分</li>
<li>特征空间不是特别大</li>
</ol>

<p>考虑一个数据集的类型分布为 0 或 1 两种，我们需要对分布在其上的数据进行类别划分，也就是说在一个数集上，$f(x)\to{0,1}$，那么我们使用 sigmoid 核函数对类型进行激活，其公式如下</p>

<p>$$
g(z) = \frac{1}{1+e^{-z}}
$$</p>

<p>通过绘制他的图形，可以看到其是个在坐标轴上的 S 型曲线，如图所示
<img src="http://cdn.qiniu.gsj987.cn/201905031053_435.png?imageslim" alt="sigmoid 函数图形" />
可以看到，当图形在 $(0,1)$ 之间分布区分，在 $z\to-\infty$ 时，类别趋近 0，在 $z\to\infty$ 时，类别趋近 1，且两者分别在 0 轴附近进行显著区分，以 0.5 作为分界线。所以我们只需要让我们的两个类别的数据在 0 轴左右尽可能的相互远离，类别就会在 sigmoid 函数上显现。那么我们设 $h_\theta(x)$ 为变量$x$在线性权重为 $\theta$ 时的类别为 1 概率，即，设$x$的线性函数：</p>

<p>$$
z = \theta_0 + \theta_1x_1 + \theta_2x_2 &hellip; + \theta_nx_n = \theta^Tx
$$</p>

<p>那么他在 sigmoid 核函数的值就是其数据类别为 1 的概率，也就是：</p>

<p>$$
h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}
$$</p>

<p>我们就把分类问题，转换成了求线性参数 $\theta$，让 $h_\theta(x)$ 的值更接近我们样本数据的类别分布，把一个非线性的问题，转换成了线性问题。所以可以说线性回归是一切机器学习算法的基础。</p>

<h3 id="损失函数">损失函数</h3>

<p>我们让 $h_\theta(x)$ 为数据类别为 1 时的概率，因为类型是二元的，我们可以得到各类别的概率：</p>

<p>$$
P(y=1|x;\theta) = h_\theta(x)
$$
$$
P(y=0|x;\theta) = 1 - h_\theta(x)
$$</p>

<p>又因为类别不是 0 就是 1，不妨我们可以做一个统一的公式：</p>

<p>$$
P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}
$$</p>

<p>又因为所有数据都是相互独立的，所以我们可以写出如下的似然函数：</p>

<p>$$
\begin{align}
L(\theta) &amp;=  P(y|x;\theta)\\<br />
  &amp;= \prod P(y_i|x_i;\theta)\\<br />
  &amp;= \prod (h_\theta(x_i))^y_i(1-h_\theta(x_i))^{1-y_i}
\end{align}
$$</p>

<p>我们求其对数，将乘法简化为加法：</p>

<p>$$
\begin{array}{lcl}
l(\theta) &amp; = &amp; logL(\theta) \\<br />
&amp; = &amp; \sum y_ilogh(x_i)+(1-y_i)log(1-h(x_i))
\end{array}
$$</p>

<p>现在我们想求得最接近数据类型分布的 $\theta$，也就是取值 $\theta$ 让 $l$ 的值最大，而这个 $l$ 正是我们的损失函数（的反数，实际使用的时候取负就行了）。求值过程也就是最大似然估计法，实际操作中，我们用梯度上升法，也就是对每次迭代的 $\theta$ 迭代一个在其位置的导数，令其快速接近最大似然值:</p>

<p>$$
\theta_{j+1} = \theta_j + \alpha (y_j - h_\theta(x_j))x_j
$$</p>

<h2 id="生成模拟数据">生成模拟数据</h2>

<p>有了以上的理论知识，我们可以进行实验。首先我们创建一系列模拟数据，创建的两组相互区分的二维数据，假设两组数据的分布接近 $(-1,-1)$ 和 $(1,1,)$，那么算法应该能把两组数据区分到 $y_0=(-1,-1)$ 和 $y_1=(1,1)$，假设分布满足高斯分布，则创建数据：</p>

<pre><code class="language-python">import numpy as np

N = 100
# 创建0.1为协方差的，均值在(-1,-1)附近的，满足高斯分布的2维数据集
x_zeros = np.random.multivariate_normal(
    mean=np.array((-1,-1)),
    cov=.1*np.eye(2),
    size=(N//2,)
)
y_zeros = np.zeros((N//2,))

# 创建0.1为协方差的，均值在(1,1)附近的，满足高斯分布的2维数据集
x_ones = np.random.multivariate_normal(
    mean=np.array((1,1)),
    cov=.1*np.eye(2),
    size=(N//2,)
)
y_ones = np.ones((N//2,))
</code></pre>

<p>我们绘制一下这个图像:</p>

<pre><code class="language-python">%matplotlib inline
import matplotlib
import numpy as np
import matplotlib.pyplot as plt

plt.scatter([x[0] for x in x_zeros], [x[1] for x in x_zeros], c=&quot;blue&quot;)
plt.scatter([x[0] for x in x_ones], [x[1] for x in x_ones], c=&quot;red&quot;)
</code></pre>

<p><img src="http://cdn.qiniu.gsj987.cn/201905031252_551.png?imageslim" alt="数据分布图" /></p>

<p>我们生成了两组数据，他们在二维空间中明显区分。</p>

<h2 id="创建训练网络">创建训练网络</h2>

<p>通过理论分析，我们创建训练网络：</p>

<pre><code class="language-python">import tensorflow as tf

with tf.name_scope(&quot;placeholders&quot;):
    x = tf.placeholder(tf.float32, (N, 2))
    y = tf.placeholder(tf.float32, (N,))
with tf.name_scope(&quot;weights&quot;):
    W = tf.Variable(tf.random_normal((2,1)))
    b = tf.Variable(tf.random_normal((1,)))
with tf.name_scope(&quot;prediction&quot;):
    # 创建 z 函数的定义
    y_logit = tf.squeeze(tf.matmul(x,W) + b)
    # 利用 sigmoid 函数计算类别
    y_one_prob = tf.sigmoid(y_logit)
    # 四舍五入求整获得类型
    y_pred = tf.round(y_one_prob)
with tf.name_scope(&quot;loss&quot;):
    # 定义损失函数，这里使用的是交叉熵损失函数，本质上和负对数似然损失函数是一样的
    entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y)
    l = tf.reduce_sum(entropy)
with tf.name_scope('optim'):
    # 以 0.01 为步长，定义梯度下降法
    train_op = tf.train.AdamOptimizer(0.01).minimize(l)
with tf.name_scope(&quot;summaries&quot;):
    tf.summary.scalar(&quot;loss&quot;, l)
    merged = tf.summary.merge_all()
</code></pre>

<h2 id="迭代训练">迭代训练</h2>

<p>我们对训练网络进行迭代训练：</p>

<pre><code class="language-python">n_steps = 1000 # 训练迭代 1000 次
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(n_steps):
        feed_dict = {x: x_np, y: y_np}
        _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)
        print(&quot;loss: %f&quot; % loss)
        train_writer.add_summary(summary, i)

    # Get weights
    w_final, b_final = sess.run([W, b])

    # Make Predictions
    y_pred_np = sess.run(y_pred, feed_dict={x: x_np})
</code></pre>

<p>得到训练结果</p>

<p><img src="http://cdn.qiniu.gsj987.cn/201905031307_610.png?imageslim" alt="训练结果" /></p>

<p>可以看到，数据的损失函数在 1000 次迭代后，降到了 0.22</p>

<h2 id="评估训练结果">评估训练结果</h2>

<p>我们使用 sklearn 的 accuracy_score 来计算分类准确性，他是计算所有分类正确的比例，即分类正确的数量比上总数量的比例：</p>

<pre><code class="language-python">from sklearn.metrics import accuracy_score

score = accuracy_score(y_np, y_pred_np)
print(&quot;分类指标: &quot;, score)
&gt;&gt;&gt; 分类指标 1.0
</code></pre>

<p>我们可以看到，所有的数据都被正确的分类了。
我们再绘制分类函数的图像，以获得更直观的体现：</p>

<pre><code class="language-python">from scipy.special import logit

plt.clf()
plt.xlabel(&quot;x&quot;)
plt.ylabel(&quot;y&quot;)
plt.title(&quot;True Model versus Learned Model &quot;)

x_left = -2
# 计算概率为 0.5 时，x2 所在代位置
y_left = (1./w_final[1]) * (-b_final + logit(.5) - w_final[0]*x_left)

x_right = 2
# 计算概率为 0.5 时，x2 所在代位置
y_right = (1./w_final[1]) * (-b_final + logit(.5) - w_final[0]*x_right)

plt.scatter([x[0] for x in x_zeros], [x[1] for x in x_zeros], c=&quot;blue&quot;)
plt.scatter([x[0] for x in x_ones], [x[1] for x in x_ones], c=&quot;red&quot;)

plt.plot([x_left, x_right], [y_left, y_right], color='k')
</code></pre>

<p>得到图像：</p>

<p><img src="http://cdn.qiniu.gsj987.cn/201905031308_244.png?imageslim" alt="分类结果显示" /></p>

<p>可以看到数据被合理区分了。
再使用命令查看线性函数计算的下降过程:</p>

<pre><code class="language-sh">tensorboard --logdir logs/train
</code></pre>

<p>得到图像：</p>

<p><img src="http://cdn.qiniu.gsj987.cn/201905031309_18.png?imageslim" alt="损失函数下降曲线" /></p>

<p>我们可以看到损失函数的下降基本达到了其极限。</p>

<h2 id="问题回顾">问题回顾</h2>

<p>我在运行中遇到了如下问题</p>

<pre><code>---------------------------------------------------------------------------  
TypeError Traceback (most recent call last) 
&lt;ipython-input-3-8562f2a61f5e&gt; in &lt;module&gt;
6 mean=np.array((-1,-1)),
7 cov=.1*np.eye(2),  
----&gt; 8  size=(N/2,)   
9 )  
10 y_zeros = np.zeros((N/2,))

mtrand.pyx in mtrand.RandomState.multivariate_normal()
mtrand.pyx in mtrand.RandomState.standard_normal()
mtrand.pyx in mtrand.cont0_array()
TypeError: 'float' object cannot be interpreted as an integer
</code></pre>

<p>这是因为在 python3 中，除号 $/$ 默认是返回浮点数，需要像 python2 一样返回整数的话，需要用双除，即 $//$</p>

<h2 id="总结">总结</h2>

<p>本文学习了逻辑回归的基本概念，并用 tensorflow 实现了逻辑回归的基本操作。其基本操作也如线性回归一样，就是 定义模型，设定损失函数，迭代，评估。逻辑回归的公式虽然多，但是基本思路还是线性回归的思路，同时他也是机器学习的重要方法，特别是 sigmoid 函数，是最常见的激活函数之一，非常重要，我们在后续的学习中还会反复遇到他。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88">https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>

                        </div>

                        


                        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/tensorflow-experience-1/">Tensorflow 体验篇-1 使用 Tensorflow 做线性回归</a></li>
        
        <li><a href="/posts/tensorflow-experience-0/">Tensorflow 体验篇-0 安装</a></li>
        
        <li><a href="/about/">关于我</a></li>
        
        <li><a href="/posts/what-can-prisma-io-do/">Pisma.io 可以用来做什么？</a></li>
        
        <li><a href="/archives/">归档</a></li>
        
    </ul>
</div>


                        <div class="post-meta meta-tags">
                            
                            <ul class="clearfix">
                                
                                <li><a href="https://gsj987.github.io/tags/tensorflow">tensorflow</a></li>
                                
                            </ul>
                            
                        </div>
                    </article>
                    
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "gsj987s-blog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    
    
                </div>
            </div>
            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://gsj987.github.io/">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://gsj987.github.io/posts/tensorflow-experience-2/" title="Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归">Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/what-can-prisma-io-do/" title="Pisma.io 可以用来做什么？">Pisma.io 可以用来做什么？</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/tensorflow-experience-1/" title="Tensorflow 体验篇-1 使用 Tensorflow 做线性回归">Tensorflow 体验篇-1 使用 Tensorflow 做线性回归</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/tensorflow-experience-0/" title="Tensorflow 体验篇-0 安装">Tensorflow 体验篇-0 安装</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">分类</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://gsj987.github.io/categories/machine-learning/">machine-learning(3)</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/categories/software-engineering/">software-engineering(1)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">标签</h3>
<div class="tagcloud">
    
    <a href="https://gsj987.github.io/tags/architecture/">architecture</a>
    
    <a href="https://gsj987.github.io/tags/ddd/">ddd</a>
    
    <a href="https://gsj987.github.io/tags/graphql/">graphql</a>
    
    <a href="https://gsj987.github.io/tags/tensorflow/">tensorflow</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://gsj987.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2019 <a href="https://gsj987.github.io/">gsj987的博客 By gsj987</a>.
        Powered by <a rel="nofollow noreferer noopener" href="https://gohugo.io" target="_blank">Hugo</a>.
        <a href="https://www.flysnow.org/" target="_blank">Theme</a> based on <a href="https://github.com/rujews/maupassant-hugo" target="_blank">maupassant</a>.
        
    </div>
</footer>


    <script type="text/javascript">
    
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())

    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
    </script>
    <script type="text/javascript" src="/js/prism.js" async="true"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-59884936-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>






</body>
</html>
