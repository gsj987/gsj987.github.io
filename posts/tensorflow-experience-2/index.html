<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.68.3" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归 | gsj987的博客</title>
    <meta property="og:title" content="Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归 - gsj987的博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content="2019-05-03T00:00:00&#43;08:00">
        
        
    <meta property="article:modified_time" content="2019-05-03T00:00:00&#43;08:00">
        
    <meta name="Keywords" content="架构,python,前端,xamarin,软件工程,机器学习,机器视觉,c#,angular">
    <meta name="description" content="Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归">
        
    <meta name="author" content="gsj987">
    <meta property="og:url" content="https://gsj987.github.io/posts/tensorflow-experience-2/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
        <link rel="stylesheet" href="/css/prism.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    


    
    
</head>

<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://gsj987.github.io/">
                        gsj987的博客
                    </a>
                
                <p class="description">技术学习和创业思考</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://gsj987.github.io/">首页</a>
                    
                    <a  href="https://gsj987.github.io/archives/" title="归档">归档</a>
                    
                    <a  href="https://gsj987.github.io/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <article class="post">
                        <header>
                            <h1 class="post-title">Tensorflow 体验篇-2 使用 Tensorflow 做逻辑回归</h1>
                        </header>
                        <date class="post-meta meta-date">
                            2019年5月3日
                        </date>
                        
                        <div class="post-meta">
                            <span>|</span>
                            
                                <span class="meta-category"><a href="https://gsj987.github.io/categories/machine-learning">machine-learning</a></span>
                            
                        </div>
                        
                        
                        
                        <div class="clear">
                            <div class="toc-article">
                                <div class="toc-title">文章目录</div>
                                <nav id="TableOfContents">
  <ul>
    <li><a href="#逻辑回归">逻辑回归</a>
      <ul>
        <li><a href="#损失函数">损失函数</a></li>
      </ul>
    </li>
    <li><a href="#生成模拟数据">生成模拟数据</a></li>
    <li><a href="#创建训练网络">创建训练网络</a></li>
    <li><a href="#迭代训练">迭代训练</a></li>
    <li><a href="#评估训练结果">评估训练结果</a></li>
    <li><a href="#问题回顾">问题回顾</a></li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
                            </div>
                        </div>
                        
                        <div class="post-content">
                            <h2 id="逻辑回归">逻辑回归</h2>
<p>逻辑回归是机器学习中最重要的概念之一。所谓逻辑回归就是在几组数据集中，利用广义线性回归的方法，对数据进行分类的方法。虽然他叫回归，但本质上是利用回归方法做了分类。其使用前提是：</p>
<ol>
<li>数据符合伯努利二项分布<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>，也就是说各项分类之间相互独立，每次成功的概率为 p，即$x,y\sim B(\pm1,p)$</li>
<li>样本数据线性可分</li>
<li>特征空间不是特别大</li>
</ol>
<p>考虑一个数据集的类型分布为 0 或 1 两种，我们需要对分布在其上的数据进行类别划分，也就是说在一个数集上，$f(x)\to{0,1}$，那么我们使用 sigmoid 核函数对类型进行激活，其公式如下</p>
<p>$$
g(z) = \frac{1}{1+e^{-z}}
$$</p>
<p>通过绘制他的图形，可以看到其是个在坐标轴上的 S 型曲线，如图所示
<img src="http://cdn.qiniu.gsj987.cn/201905031053_435.png?imageslim" alt="sigmoid 函数图形">
可以看到，当图形在 $(0,1)$ 之间分布区分，在 $z\to-\infty$ 时，类别趋近 0，在 $z\to\infty$ 时，类别趋近 1，且两者分别在 0 轴附近进行显著区分，以 0.5 作为分界线。所以我们只需要让我们的两个类别的数据在 0 轴左右尽可能的相互远离，类别就会在 sigmoid 函数上显现。那么我们设 $h_\theta(x)$ 为变量$x$在线性权重为 $\theta$ 时的类别为 1 概率，即，设$x$的线性函数：</p>
<p>$$
z = \theta_0 + \theta_1x_1 + \theta_2x_2 &hellip; + \theta_nx_n = \theta^Tx
$$</p>
<p>那么他在 sigmoid 核函数的值就是其数据类别为 1 的概率，也就是：</p>
<p>$$
h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}
$$</p>
<p>我们就把分类问题，转换成了求线性参数 $\theta$，让 $h_\theta(x)$ 的值更接近我们样本数据的类别分布，把一个非线性的问题，转换成了线性问题。所以可以说线性回归是一切机器学习算法的基础。</p>
<h3 id="损失函数">损失函数</h3>
<p>我们让 $h_\theta(x)$ 为数据类别为 1 时的概率，因为类型是二元的，我们可以得到各类别的概率：</p>
<p>$$
P(y=1|x;\theta) = h_\theta(x)
$$
$$
P(y=0|x;\theta) = 1 - h_\theta(x)
$$</p>
<p>又因为类别不是 0 就是 1，不妨我们可以做一个统一的公式：</p>
<p>$$
P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}
$$</p>
<p>又因为所有数据都是相互独立的，所以我们可以写出如下的似然函数：</p>
<p>$$
\begin{align}
L(\theta) &amp;=  P(y|x;\theta)\\\<br>
&amp;= \prod P(y_i|x_i;\theta)\\\<br>
&amp;= \prod (h_\theta(x_i))^y_i(1-h_\theta(x_i))^{1-y_i}
\end{align}
$$</p>
<p>我们求其对数，将乘法简化为加法：</p>
<p>$$
\begin{array}{lcl}
l(\theta) &amp; = &amp; logL(\theta) \\\<br>
&amp; = &amp; \sum y_ilogh(x_i)+(1-y_i)log(1-h(x_i))
\end{array}
$$</p>
<p>现在我们想求得最接近数据类型分布的 $\theta$，也就是取值 $\theta$ 让 $l$ 的值最大，而这个 $l$ 正是我们的损失函数（的反数，实际使用的时候取负就行了）。求值过程也就是最大似然估计法，实际操作中，我们用梯度上升法，也就是对每次迭代的 $\theta$ 迭代一个在其位置的导数，令其快速接近最大似然值:</p>
<p>$$
\theta_{j+1} = \theta_j + \alpha (y_j - h_\theta(x_j))x_j
$$</p>
<h2 id="生成模拟数据">生成模拟数据</h2>
<p>有了以上的理论知识，我们可以进行实验。首先我们创建一系列模拟数据，创建的两组相互区分的二维数据，假设两组数据的分布接近 $(-1,-1)$ 和 $(1,1,)$，那么算法应该能把两组数据区分到 $y_0=(-1,-1)$ 和 $y_1=(1,1)$，假设分布满足高斯分布，则创建数据：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

N <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
<span style="color:#75715e"># 创建0.1为协方差的，均值在(-1,-1)附近的，满足高斯分布的2维数据集</span>
x_zeros <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>multivariate_normal(
    mean<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array((<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)),
    cov<span style="color:#f92672">=.</span><span style="color:#ae81ff">1</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>eye(<span style="color:#ae81ff">2</span>),
    size<span style="color:#f92672">=</span>(N<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>,)
)
y_zeros <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((N<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>,))

<span style="color:#75715e"># 创建0.1为协方差的，均值在(1,1)附近的，满足高斯分布的2维数据集</span>
x_ones <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>multivariate_normal(
    mean<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array((<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)),
    cov<span style="color:#f92672">=.</span><span style="color:#ae81ff">1</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>eye(<span style="color:#ae81ff">2</span>),
    size<span style="color:#f92672">=</span>(N<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>,)
)
y_ones <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones((N<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>,))
</code></pre></div><p>我们绘制一下这个图像:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> matplotlib
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

plt<span style="color:#f92672">.</span>scatter([x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_zeros], [x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_zeros], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;blue&#34;</span>)
plt<span style="color:#f92672">.</span>scatter([x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_ones], [x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_ones], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>)
</code></pre></div><p><img src="http://cdn.qiniu.gsj987.cn/201905031252_551.png?imageslim" alt="数据分布图"></p>
<p>我们生成了两组数据，他们在二维空间中明显区分。</p>
<h2 id="创建训练网络">创建训练网络</h2>
<p>通过理论分析，我们创建训练网络：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#34;placeholders&#34;</span>):
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, (N, <span style="color:#ae81ff">2</span>))
    y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, (N,))
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#34;weights&#34;</span>):
    W <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random_normal((<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>)))
    b <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random_normal((<span style="color:#ae81ff">1</span>,)))
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#34;prediction&#34;</span>):
    <span style="color:#75715e"># 创建 z 函数的定义</span>
    y_logit <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>squeeze(tf<span style="color:#f92672">.</span>matmul(x,W) <span style="color:#f92672">+</span> b)
    <span style="color:#75715e"># 利用 sigmoid 函数计算类别</span>
    y_one_prob <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>sigmoid(y_logit)
    <span style="color:#75715e"># 四舍五入求整获得类型</span>
    y_pred <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>round(y_one_prob)
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#34;loss&#34;</span>):
    <span style="color:#75715e"># 定义损失函数，这里使用的是交叉熵损失函数，本质上和负对数似然损失函数是一样的</span>
    entropy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>sigmoid_cross_entropy_with_logits(logits<span style="color:#f92672">=</span>y_logit, labels<span style="color:#f92672">=</span>y)
    l <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_sum(entropy)
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;optim&#39;</span>):
    <span style="color:#75715e"># 以 0.01 为步长，定义梯度下降法</span>
    train_op <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>AdamOptimizer(<span style="color:#ae81ff">0.01</span>)<span style="color:#f92672">.</span>minimize(l)
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#34;summaries&#34;</span>):
    tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#34;loss&#34;</span>, l)
    merged <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>merge_all()
</code></pre></div><h2 id="迭代训练">迭代训练</h2>
<p>我们对训练网络进行迭代训练：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">n_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># 训练迭代 1000 次</span>
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
    sess<span style="color:#f92672">.</span>run(tf<span style="color:#f92672">.</span>global_variables_initializer())
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(n_steps):
        feed_dict <span style="color:#f92672">=</span> {x: x_np, y: y_np}
        _, summary, loss <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run([train_op, merged, l], feed_dict<span style="color:#f92672">=</span>feed_dict)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;loss: </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> loss)
        train_writer<span style="color:#f92672">.</span>add_summary(summary, i)

    <span style="color:#75715e"># Get weights</span>
    w_final, b_final <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run([W, b])

    <span style="color:#75715e"># Make Predictions</span>
    y_pred_np <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run(y_pred, feed_dict<span style="color:#f92672">=</span>{x: x_np})
</code></pre></div><p>得到训练结果</p>
<p><img src="http://cdn.qiniu.gsj987.cn/201905031307_610.png?imageslim" alt="训练结果"></p>
<p>可以看到，数据的损失函数在 1000 次迭代后，降到了 0.22</p>
<h2 id="评估训练结果">评估训练结果</h2>
<p>我们使用 sklearn 的 accuracy_score 来计算分类准确性，他是计算所有分类正确的比例，即分类正确的数量比上总数量的比例：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score

score <span style="color:#f92672">=</span> accuracy_score(y_np, y_pred_np)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;分类指标: &#34;</span>, score)
<span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#960050;background-color:#1e0010">分类指标</span> <span style="color:#ae81ff">1.0</span>
</code></pre></div><p>我们可以看到，所有的数据都被正确的分类了。
我们再绘制分类函数的图像，以获得更直观的体现：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> scipy.special <span style="color:#f92672">import</span> logit

plt<span style="color:#f92672">.</span>clf()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;True Model versus Learned Model &#34;</span>)

x_left <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>
<span style="color:#75715e"># 计算概率为 0.5 时，x2 所在代位置</span>
y_left <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span>w_final[<span style="color:#ae81ff">1</span>]) <span style="color:#f92672">*</span> (<span style="color:#f92672">-</span>b_final <span style="color:#f92672">+</span> logit(<span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>) <span style="color:#f92672">-</span> w_final[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">*</span>x_left)

x_right <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
<span style="color:#75715e"># 计算概率为 0.5 时，x2 所在代位置</span>
y_right <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span>w_final[<span style="color:#ae81ff">1</span>]) <span style="color:#f92672">*</span> (<span style="color:#f92672">-</span>b_final <span style="color:#f92672">+</span> logit(<span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>) <span style="color:#f92672">-</span> w_final[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">*</span>x_right)

plt<span style="color:#f92672">.</span>scatter([x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_zeros], [x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_zeros], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;blue&#34;</span>)
plt<span style="color:#f92672">.</span>scatter([x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_ones], [x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_ones], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>)

plt<span style="color:#f92672">.</span>plot([x_left, x_right], [y_left, y_right], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k&#39;</span>)
</code></pre></div><p>得到图像：</p>
<p><img src="http://cdn.qiniu.gsj987.cn/201905031308_244.png?imageslim" alt="分类结果显示"></p>
<p>可以看到数据被合理区分了。
再使用命令查看线性函数计算的下降过程:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">tensorboard --logdir logs/train
</code></pre></div><p>得到图像：</p>
<p><img src="http://cdn.qiniu.gsj987.cn/201905031309_18.png?imageslim" alt="损失函数下降曲线"></p>
<p>我们可以看到损失函数的下降基本达到了其极限。</p>
<h2 id="问题回顾">问题回顾</h2>
<p>我在运行中遇到了如下问题</p>
<pre><code>---------------------------------------------------------------------------  
TypeError Traceback (most recent call last) 
&lt;ipython-input-3-8562f2a61f5e&gt; in &lt;module&gt;
6 mean=np.array((-1,-1)),
7 cov=.1*np.eye(2),  
----&gt; 8  size=(N/2,)   
9 )  
10 y_zeros = np.zeros((N/2,))

mtrand.pyx in mtrand.RandomState.multivariate_normal()
mtrand.pyx in mtrand.RandomState.standard_normal()
mtrand.pyx in mtrand.cont0_array()
TypeError: 'float' object cannot be interpreted as an integer
</code></pre><p>这是因为在 python3 中，除号 $/$ 默认是返回浮点数，需要像 python2 一样返回整数的话，需要用双除，即 $//$</p>
<h2 id="总结">总结</h2>
<p>本文学习了逻辑回归的基本概念，并用 tensorflow 实现了逻辑回归的基本操作。其基本操作也如线性回归一样，就是 定义模型，设定损失函数，迭代，评估。逻辑回归的公式虽然多，但是基本思路还是线性回归的思路，同时他也是机器学习的重要方法，特别是 sigmoid 函数，是最常见的激活函数之一，非常重要，我们在后续的学习中还会反复遇到他。</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88">https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

                        </div>

                        


                        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/tensorflow-experience-1/">Tensorflow 体验篇-1 使用 Tensorflow 做线性回归</a></li>
        
        <li><a href="/posts/tensorflow-experience-0/">Tensorflow 体验篇-0 安装</a></li>
        
        <li><a href="/about/">关于我</a></li>
        
        <li><a href="/posts/what-can-prisma-io-do/">Pisma.io 可以用来做什么？</a></li>
        
        <li><a href="/archives/">归档</a></li>
        
    </ul>
</div>


                        <div class="post-meta meta-tags">
                            
                            <ul class="clearfix">
                                
                                <li><a href="https://gsj987.github.io/tags/tensorflow">tensorflow</a></li>
                                
                            </ul>
                            
                        </div>
                    </article>
                    
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "gsj987s-blog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    
    
                </div>
            </div>
            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://gsj987.github.io/">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-6/" title="聪明的笔记6 - 构建想法">聪明的笔记6 - 构建想法</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-5/" title="聪明的笔记5 - 记聪明的笔记">聪明的笔记5 - 记聪明的笔记</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-4/" title="聪明的笔记4 - 为了理解而阅读">聪明的笔记4 - 为了理解而阅读</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-3/" title="聪明的笔记3 - ﻿分离和连接任务">聪明的笔记3 - ﻿分离和连接任务</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-2/" title="聪明的笔记2 - 四个重要原则">聪明的笔记2 - 四个重要原则</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/how-to-take-smart-notes-1/" title="聪明的笔记1 - 介绍">聪明的笔记1 - 介绍</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/tensorflow-experience-4/" title="Tensorflow 体验篇-4 卷积网络和图像分类">Tensorflow 体验篇-4 卷积网络和图像分类</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/tensorflow-experience-3/" title="Tensorflow 体验篇-3 全连接网络">Tensorflow 体验篇-3 全连接网络</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/use-android-library-on-raspberry-pi-with-libhybris/" title="利用 libhybris 在树莓派上使用 Android 库">利用 libhybris 在树莓派上使用 Android 库</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/posts/save-and-paste-image-from-clipboard-in-orgmode/" title="在 OrgMode 中保存并粘贴剪切板中的图片">在 OrgMode 中保存并粘贴剪切板中的图片</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">分类</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://gsj987.github.io/categories/emacs/">emacs(1)</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/categories/linux/">linux(1)</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/categories/machine-learning/">machine-learning(5)</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/categories/reading-notes/">reading-notes(6)</a>
    </li>
    
    <li>
        <a href="https://gsj987.github.io/categories/software-engineering/">software-engineering(1)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">标签</h3>
<div class="tagcloud">
    
    <a href="https://gsj987.github.io/tags/android/">android</a>
    
    <a href="https://gsj987.github.io/tags/architecture/">architecture</a>
    
    <a href="https://gsj987.github.io/tags/cnn/">cnn</a>
    
    <a href="https://gsj987.github.io/tags/ddd/">ddd</a>
    
    <a href="https://gsj987.github.io/tags/elisp/">elisp</a>
    
    <a href="https://gsj987.github.io/tags/graphql/">graphql</a>
    
    <a href="https://gsj987.github.io/tags/how-to-take-smart-notes/">how-to-take-smart-notes</a>
    
    <a href="https://gsj987.github.io/tags/raspberry-pi/">raspberry-pi</a>
    
    <a href="https://gsj987.github.io/tags/study-method/">study-method</a>
    
    <a href="https://gsj987.github.io/tags/tensorflow/">tensorflow</a>
    
    <a href="https://gsj987.github.io/tags/windows/">windows</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://gsj987.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2021 <a href="https://gsj987.github.io/">gsj987的博客 By gsj987</a>.
        Powered by <a rel="nofollow noreferer noopener" href="https://gohugo.io" target="_blank">Hugo</a>.
        <a href="https://www.flysnow.org/" target="_blank">Theme</a> based on <a href="https://github.com/rujews/maupassant-hugo" target="_blank">maupassant</a>.
        
    </div>
</footer>


    <script type="text/javascript">
    
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())

    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
    </script>
    <script type="text/javascript" src="/js/prism.js" async="true"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-59884936-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>






</body>
</html>
